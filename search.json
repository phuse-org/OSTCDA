[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Open Source Technology in Clinical Data Analysis",
    "section": "",
    "text": "Preface\nThe information contained in this Quarto book aims to comprehensively address the most important questions related to deploying open source solutions for clinical data analytics in the pharmaceutical and vaccine development industry.\nWe are developing this manuscript in the open and accepting contributions by the community via our GitHub repository’s Discussions tab. Please contribute your thoughts, perspectives, references, citations, and links through that mechanism. We’d like to be able to attribute your ideas to you, so providing the rationale supporting your thoughts will strengthen your argument. Please be as thoughtful and thorough in your contributions as you can! You can also upvote questions and/or responses that you find particularly valuable.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#thank-you",
    "href": "index.html#thank-you",
    "title": "Open Source Technology in Clinical Data Analysis",
    "section": "Thank you",
    "text": "Thank you\nThank you to PHUSE for supporting this endeavor. And thank you to YOU for your thoughtful contributions to the effort.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "1  What is Open Source?",
    "section": "",
    "text": "1.1 What is Open Source?\nThe Open Source Initiative delineates a number of characteristics of what it means to be open source, including free distribution, available source code, and the ability to create derived works.\nAccording to Merriam-Webster, open source is “having the source code freely available for possible modification and redistribution”.\nWikipedia defines open-source software (OSS) as a computer software that is released under a license in which the copyright holder grants users the rights to use, study, change and distribute the software and its source code to anyone and for any purpose.\nAll three of these sources refer to the ability to see the code, use the code, change the code, and share the code. And to be able to do so without any cost.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Open Source?</span>"
    ]
  },
  {
    "objectID": "summary.html#what-is-open-source",
    "href": "summary.html#what-is-open-source",
    "title": "1  What is Open Source?",
    "section": "",
    "text": "1.1.1 How is this enabled?\nFundamentally, the code is owned by someone - by some entity, whether an individual, an organization, or a group of other entities. The owner of the code have the right to disseminate the code openly and describe how it can be used by others. This is accomplished through a license agreement (discussed in another section). For any piece of open source code, the owner of that code has decided to release it publicly with an associated license that defines how others may use or modify the code.\nIn a paper entitled *Open Source Technologies in Clinical Research, as part of the 2020 PHUSE US Connect, Bruce Wienckowski et al. write that “open source software includes permission to use the source code, design documents, or content of the product.” This is in contrast to proprietary software which is not typically distributed free of charge and “typically has licensed limitations on how that software can be used.”\nData submitted for review by a health authority to approve a medicine, therapy, or vaccine into the market it governs are expected to be accurate, reproducible, and traceable from the point of collection to the final analytic report. The ability to demonstrate the integrity of all data transformations has been perceived to be more challenging with open source solutions (relative to proprietary or commercial solutions).\nIn this publication, we aim to explore the numerous questions that have been raised by practitioners of data analytics for clinical research. These questions are aimed at managing the perceived risk of leveraging tools built on open source software for analyzing clinical trial data to support market applications of medicines, therapies, and vaccines based on evidence of safety and efficacy. The answers to some of these questions are becoming well understood in the industry while other answers are less complete. Our objective is to comprehensively compile this knowledge for ease of reference by others.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Open Source?</span>"
    ]
  },
  {
    "objectID": "summary.html#discussion",
    "href": "summary.html#discussion",
    "title": "1  What is Open Source?",
    "section": "1.2 Discussion",
    "text": "1.2 Discussion\nYou may continue to contribute to this discussion here in GitHub Discussions:\nWhat is open source?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is Open Source?</span>"
    ]
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "2  (-) Why Open Source?",
    "section": "",
    "text": "2.1 What is the ‘why’ for using open source solutions in pharma clinical data analytics?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>(-) Why Open Source?</span>"
    ]
  },
  {
    "objectID": "why.html#what-is-the-why-for-using-open-source-solutions-in-pharma-clinical-data-analytics",
    "href": "why.html#what-is-the-why-for-using-open-source-solutions-in-pharma-clinical-data-analytics",
    "title": "2  (-) Why Open Source?",
    "section": "",
    "text": "What is the attraction to open source solutions?\nWhy do users like open source solutions?\nWhy are leaders of organizations in Data Management, Biostatistics, and Programming devoting resources toward the development, testing, and adoption of open source solutions?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>(-) Why Open Source?</span>"
    ]
  },
  {
    "objectID": "why.html#discussion",
    "href": "why.html#discussion",
    "title": "2  (-) Why Open Source?",
    "section": "2.2 Discussion",
    "text": "2.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nWhat is the ‘why’ for open source?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>(-) Why Open Source?</span>"
    ]
  },
  {
    "objectID": "trust.html",
    "href": "trust.html",
    "title": "3  (-) Establishing Trust",
    "section": "",
    "text": "3.1 Can an open source solution be trusted?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>(-) Establishing Trust</span>"
    ]
  },
  {
    "objectID": "trust.html#can-an-open-source-solution-be-trusted",
    "href": "trust.html#can-an-open-source-solution-be-trusted",
    "title": "3  (-) Establishing Trust",
    "section": "",
    "text": "How do we have confidence that an open source solution is accurate?\nWhat are the relevant considerations?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>(-) Establishing Trust</span>"
    ]
  },
  {
    "objectID": "trust.html#discussion",
    "href": "trust.html#discussion",
    "title": "3  (-) Establishing Trust",
    "section": "3.2 Discussion",
    "text": "3.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nCan an open source solution be trusted to be accurate?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>(-) Establishing Trust</span>"
    ]
  },
  {
    "objectID": "doc_trust.html",
    "href": "doc_trust.html",
    "title": "4  Documenting Trust",
    "section": "",
    "text": "4.1 How do you document your trust in an open source solution?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Trust</span>"
    ]
  },
  {
    "objectID": "doc_trust.html#how-do-you-document-your-trust-in-an-open-source-solution",
    "href": "doc_trust.html#how-do-you-document-your-trust-in-an-open-source-solution",
    "title": "4  Documenting Trust",
    "section": "",
    "text": "How do we have document our trust that an open source solution is accurate?\nHow do we know if a third-party will accept our documentation of trust?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Trust</span>"
    ]
  },
  {
    "objectID": "doc_trust.html#community-input-draft",
    "href": "doc_trust.html#community-input-draft",
    "title": "4  Documenting Trust",
    "section": "4.2 Community Input [DRAFT]",
    "text": "4.2 Community Input [DRAFT]\n\nOnce we’ve chosen our process, [we must] either demonstrate that any human action in the process is without error (quality control and quality assurance) or any machine action in the process works as intended (testing and validation). We accomplish this by demonstrating the accuracy, reproducibility and traceability of the data which is transformed through that process.\n– Michael Rimler, Can Clinical Data Processed With R Be Used in a Regulatory Submission?, PHUSE Blog, 2022\n\nThe two primary efforts which have tackled the question of documenting trust in software solutions in the industry come from:\n\nTranscelerate’s Modernization of Statistical Analytics (MSA) Framework\nR Validation Hub\n\nEach of these efforts speak to the value of accuracy, reproducibility, and traceability in establishing trust in a software solution, which must be documented in case it is ever interrogated by a third-party.\nAccording to Transcelerate’s MSA Framework:\n\nAccuracy is the “measure of correctness of software libraries that are used to generate results.”\nReproducibility indicates the ability that that result “can be recreated from the original dataset along with the associated environment, including all artifacts and dependencies.”\nTraceability “refers to the ability to trace inputs to outputs, with the main goal being to provide evidence to connect e-data, code, and environment to the final output that is produced.\n\nThe R Validation Hub cites the FDA’s Glossary of Computer System Software Development Technology in defining validation as “establishing documented evidence which provides a high degree of assurance (accuracy) that a specific process consistently (reproducibility) produces a product meeting its predetermined specifications (traceability) and quality attributes.”\nIn 2020, the R Validation Hub issued a white paper “A Risk-based Approach for Assessing R Package Accuracy within a Validated Infrastructure,” suggesting a risk assessment framework based on four criteria:\n\nPurpose\nMaintenance Good Practice (SDLC)\nCommunity Usage\nTesting\n\nEssentially, we may choose to trust a solution if that solution:\n\nis well documented\nfollows a well-defined and well-designed software development process,\nis widely used by the community, and\ncontains documentable and thorough testing of algorithms\n\nAndy Nicholls, former Chair of the R Validation Hub and co-author of the white paper, suggests that there are 3 key documents required for establishing trust in a solution:\n\nExplanation of the overall approach to validation\nExplanation of why one might be willing to accept suites of packages, full-stop. For example, when considering tidyverse or core R packages, documenting that “We’ve reviewed [list of documents] from posit (or R Foundation) and accept that they follow good practice.” may be sufficient.\nAn assessment report for each additional package, which may include both human-written interpretations and automated metrics.\n\n\n4.2.1 Useful Packages for R\nThe risk assessment framework described in the white paper has resulted in two open-sourced R packages which perform automated checks on characteristics which correlate with the four criteria:\n\nriskmetric: “a framework to quantify an R package’s”risk of use” by assessing a number of meaningful metrics designed to evaluate package development best practices, code documentation, community engagement, and development sustainability.”\nriskassessment: “an R package containing a shiny front-end to augment the utility of the {riskmetric} package within an organizational context.”\n\nIn addition, the {valtools} package “helps automate the validation of R packages used in clinical research and drug development” by providing “useful templates and helper functions for tasks that arise during project set up and development of the validation framework.”\nAnother open-sourced R package is {thevalidatoR} which is “a GitHub action that generates a validation report for an R package.”\nThese packages help a user perform and document risk assessments on R packages, which aids in justifying why that individual (or organization) places trust in the results of the functionality provided by the solution.\n\n\n4.2.2 Approaches Across Industry\nPHUSE’s End-to-End Open-Source Collaboration Guidance references a Case Studies Repository, “which contains examples from Roche, Merck and Novartis on how they approach validation and risk mitigation.” The main takeaway, according to James Black, is of “the 4 companies that shared their process for assessing R packages, each company currently takes a very different approach.” Coline Zeballos presented on Roche’s to package validation at the R/Pharma conference, both in 2021 and 2022 (co-presenting with Doug Kelkhoff).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Trust</span>"
    ]
  },
  {
    "objectID": "doc_trust.html#discussion",
    "href": "doc_trust.html#discussion",
    "title": "4  Documenting Trust",
    "section": "4.3 Discussion",
    "text": "4.3 Discussion\nContribute to the discussion here in GitHub Discussions:\nHow do you document your trust in an open source solution to satisfy a third-party inquiry?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Documenting Trust</span>"
    ]
  },
  {
    "objectID": "cost.html",
    "href": "cost.html",
    "title": "5  (-) Cost of Open Source",
    "section": "",
    "text": "5.1 What is the true cost of implementing open source solutions?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>(-) Cost of Open Source</span>"
    ]
  },
  {
    "objectID": "cost.html#what-is-the-true-cost-of-implementing-open-source-solutions",
    "href": "cost.html#what-is-the-true-cost-of-implementing-open-source-solutions",
    "title": "5  (-) Cost of Open Source",
    "section": "",
    "text": "Is it essentially free?\nWhat resources are required for proper implementation?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>(-) Cost of Open Source</span>"
    ]
  },
  {
    "objectID": "cost.html#discussion",
    "href": "cost.html#discussion",
    "title": "5  (-) Cost of Open Source",
    "section": "5.2 Discussion",
    "text": "5.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nWhat is the true cost of implementing open source solutions into clinical data analytic processes??",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>(-) Cost of Open Source</span>"
    ]
  },
  {
    "objectID": "reg_accept.html",
    "href": "reg_accept.html",
    "title": "6  Regulatory Acceptance",
    "section": "",
    "text": "6.1 Will the regulatory agencies accept data and analyses generated with solutions developed and available as open source?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#will-the-regulatory-agencies-accept-data-and-analyses-generated-with-solutions-developed-and-available-as-open-source",
    "href": "reg_accept.html#will-the-regulatory-agencies-accept-data-and-analyses-generated-with-solutions-developed-and-available-as-open-source",
    "title": "6  Regulatory Acceptance",
    "section": "",
    "text": "What do we know regarding data submissions to FDA?\nWhat do we know regarding data submissions to other regulatory agencies?\nAre there technical considerations for the creation of submission data packages?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#perceived-fear",
    "href": "reg_accept.html#perceived-fear",
    "title": "6  Regulatory Acceptance",
    "section": "6.2 (Perceived) Fear",
    "text": "6.2 (Perceived) Fear\nThere has been a long debate about whether regulatory agencies would accept submissions using R and Open Source tools. This is in spite of communications from agency staff for over 15 years refuting this and stating that the agency would not and could not endorse any specific software tool for sponsor submissions (Bell 2006; Soukup 2007; Drug Administration (FDA) 2015; Schuette 2018). Yet still there has been reticence from pharmaceutical industry sponsors around using R for clinical trials reporting and analysis of key endpoints. Meanwhile clinical pharmacology and pharmacometrics groups within many pharma companies have been using R for over 10 years in regulatory submissions and interactions, preparing graphics for presentation, model diagnostics and data summaries. So while some business areas within the industry are comfortable using R and other open source tools, other parts are more nervous about committing fully to an open source software solution.\nWhat is driving this nervousness then? If the regulatory agencies are telling us that they will accept submissions with R then what is stopping it from being more widely used within and across pharmaceutical companies?\nPerhaps it is down to fear of having a dossier rejected by a regulatory agency - “Refusal to file” - due to application deficiencies. In this context, could the use of open source software trigger this “Refusal to file”? Since “Refusal to file” could have a significant impact on a company’s reputation, confidence and ultimately their stock price, it is understandable that companies are cagey. Also, who would want to be first to try out this untrodden path? It is easier to follow in the footsteps of somebody else than to forge a path yourself.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#reducing-uncertainty",
    "href": "reg_accept.html#reducing-uncertainty",
    "title": "6  Regulatory Acceptance",
    "section": "6.3 (Reducing) Uncertainty",
    "text": "6.3 (Reducing) Uncertainty\n\n“…there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns — the ones we don’t know we don’t know.”\n– Donald Rumsfeld\n\nFortunately we now have a growing number of examples of companies who are on this journey towards using more open source software in drug development and, critically, in regulatory interactions and submission (Knoph 2023; Neitman 2023; Bowsher, n.d.). There is also the R Consortium Submissions Working Group (“R Consortium Submissions Working Group” 2021) - a cross industry pharma working group focusing on improving practices of R-based clinical trial regulatory submissions. This group has open dialogue with colleagues at the US FDA regulatory agency around technical issues of filing submissions using R deliverables and pilots these using open source examples in order to check and verify that submissions via the FDA electronic submissions process are received and can be validated within the agency. This eliminates some elements of fear and uncertainty from sponsors around the technical aspects, allows regulatory agency colleagues to provide feedback with the working group members in an environment which is not high-pressure or business critical to a sponsor. It is in the interest of both regulators and industry to modernise, to acknowledge a shift in tools that are being used to conduct clinical development of new therapeutics and be ready for whatever future state emerges. To be able to do this with increased confidence and mutual understanding is vital to this modernisation.\nThe Novo Nordisk experience (Knoph 2023) provides critical learnings. In their filing to US FDA, PMDA and other health authorities, they used a combination of SAS and R to prepare submission datasets and deliverables. They described their process as being an evolution, rather than revolution, using R to replicate tables and figures usually generated via SAS. Key also to the process was building an infrastructure and environment around R that would meet expectations pertaining to quality and reproducibility. This, more so than the replication of SAS output provides the backbone of “validated” work in R. They communicated in advance of submission with the regulatory authorities, which allowed both parties (sponsor and authority) to set expectations and “get ready” in good time. This did not prevent “Information Requests” from the FDA for clarification - causing anxious moments for the sponsor - but in the end this was about information sharing, reaching mutual understanding, for clarification and ensuring that the FDA internal environment would match Novo Nordisk’s rather than a refusal to accept open source software approaches. The results of their work is giving Novo Nordisk and the pharmaceutical industry generally, more confidence to move forward with R and open source tools as the core of their submission work.\nSimilarly, Roche (Neitman 2023) is spending a great deal of effort in preparation - organisationally and technologically - for submission to regulatory agencies. The common thread across both Novo Nordisk and Roche / Genentech is about preparation and dialogue within the company (with regulatory, quality assurance and process groups) and with regulatory agencies in the lead up to submission. Proper preparation prevents poor performance, as the aphorism goes.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#avoiding-doubt",
    "href": "reg_accept.html#avoiding-doubt",
    "title": "6  Regulatory Acceptance",
    "section": "6.4 (Avoiding) Doubt",
    "text": "6.4 (Avoiding) Doubt\nAs has been mentioned, the Submissions Working Group of the R Consortium is actively partnering with US FDA to pilot submissions through the agency’s electronic submissions portal. These pilot submissions are created and presented on Github as open source code, so it is possible for anyone to review what was submitted, how, and the agency’s feedback and report on which elements were successful and any issues found with the submission. The pilots are vital for sponsors to understand the mechanisms of submission using open source software like R, and for regulatory agencies to understand how to reconstitute sponsor software environments, install packages and confirm results. This dialogue reduces the likelihood of any fundamental issues with submission using open source software, but does not completely eliminate sources of potential problems. In a sense, the pilots uncover known unknowns - the things that we expect to cause issues - so that they can be discussed and addressed on both sides. The sponsor needs to be sure to provide sufficient information that the agency has the best chance of recreating the environment for reproducing the results. Through the pilot process then, both parties can understand what needs to be communicated at the time of submission to reduce unexpected findings and business critical issues that need to resolved quickly.\nThe pilots are also allowing sponsors and agencies to look at modernising the content of the submission, moving from static tables, listings and figures to more dynamic, interactive presentations through web applications and dynamic HTML presentations. This goes beyond the “evolution” described by Novo Nordisk towards a true “revolution” in what sponsors submit to agencies and how they review the contents of those submissions.\nYet still some doubts persist. If a sponsor submits analytical results using Tool X, but the agency reviewer re-analyses the data with Tool Y and sees a different result, who owns reconciling the differences? The sponsor, via a time-bound Information Request from the agency? The agency? The developer of Tool X? When the majority of analysis uses only one tool for analysis, this situation is likely to be a rare occurence. But when the toolset available to both sponsors and agencies becomes wider, then resolving these questions is likely to come up more often.\nAnd what about agencies who typically do not re-analyse sponsor data? How can the industry provide reassurance and proof that analytical environments are validated: accurate, reproducible and traceable? When installation of software into an environment is a one-step process, we can be pretty sure of consistency across analysts. But if there are multiple steps involved, and the software can change almost daily, then how do we ensure this consistency and reproducibility? This is not just the job of IT organisations within sponsor companies, but the responsibility of the individual analyst, to ensure that they are working compliant with organisational processes and in validated environments. Audit trails and traceability helps ensure this, but it is a potential source of doubt for both sponsor and regulatory authority.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#industry-experiences",
    "href": "reg_accept.html#industry-experiences",
    "title": "6  Regulatory Acceptance",
    "section": "6.5 Industry Experiences",
    "text": "6.5 Industry Experiences\nThe industry offers a diverse range of experiences that can significantly enhance your professional growth. Below is an overview of various industry experiences gathered so far:\n\n\n\n\n\n\n\n\nSponsor\nAgency\nExperiences\n\n\n\n\nRConsortium Pilot\nInfo\nFDA\nSubmitted\n\n\nAccepted\n\n\n\nNovo Nordisk\nPresentation\nFDA\nSubmitted\n\n\nBig data ADaM programmed in R and pre-announced this during Type C and B meeting packages\nRemaining ADaM in SAS and double programmed in R (where applicable)\nAll TFL in R\nFollowing requests from FDA all TFL programs and internal R packages submitted. Packages packed using pkglite.\nAdditional guidance and informal meeting with FDA statisticians on restoring R environment was held\n\n\n\nEMA\nSubmitted content using R\n\n\nNMPA\nSame as PMDA\n\n\nPMDA\nSubmitted\n\n\nBig data ADaM programmed in R and pre-announced during additional eSubmission meeting\nRemaining ADaM in SAS and double programmed in R (where applicable)\nAll TFL in R programs submitted\n\n\n\nHealth Canada\nSubmitted content using R\n\n\nRoche\nPresentation\nFDA\nSubmitted content using R\n\n\nInitial pushback from the FDA reviewer to accept R, they wanted SAS instead.\nRoche pushed back and submitted in R (based on Technical Conformance Guidance)\nKey message - acceptance of R may vary between different agency reviewers\nKey message - have the content & format discussions early with the agency\n\n\n\nEMA\nSubmitted content using R\n(no comments received so far)\n\n\nNMPA\nSubmitted content using R\n(no comments received so far)\n\n\nSwissMedic\n\n\n\n\nMerck\nFDA\nSubmitted\n\n\nMultiple successful submissions\nGxP platform available\nReproducible environment\n\n\n\nAstellas Pharma\nFDA\n(2021) for using R markdown to submit programs\nExample",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#discussion",
    "href": "reg_accept.html#discussion",
    "title": "6  Regulatory Acceptance",
    "section": "6.6 Discussion",
    "text": "6.6 Discussion\nContribute to the discussion here in GitHub Discussions:\nWill the FDA accept data and analyses generated with solutions developed and available as open source?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "reg_accept.html#references",
    "href": "reg_accept.html#references",
    "title": "6  Regulatory Acceptance",
    "section": "6.7 References",
    "text": "6.7 References\nBell, B “Issues with Open Source Statistical Software in Industry: Validation, Legal Issues, and Regulatory Requirements” ASA JSM 2006.\nSukop, M “Using R: Perspectives of a FDA Statistical RevieweR”. UseR 2007 https://www.r-project.org/conferences/useR-2007/program/presentations/soukup.pdf\nU.S. Food & Drug Administration. (2015, May 6).Statistical Software Clarifing Statement. Retrieved from FDA.gov: https://www.fda.gov/media/109552/download\n\n\n\n\nBell, B. 2006. “Issues with Open Source Statistical Software in Industry: Validation, Legal Issues, and Regulatory Requirements.” https://ww2.amstat.org/meetings/jsm/2006/onlineprogram/index.cfm?fuseaction=people_index&letter=B.\n\n\nBowsher, P. n.d. “Open-Source-in-New-Drug-Applications-NDAs-FDA.” https://github.com/philbowsher/Open-Source-in-New-Drug-Applications-NDAs-FDA.\n\n\nDrug Administration (FDA), U. S. Food &. 2015. “Statistical Software Clarifying Statement.” https://www.fda.gov/media/161196/download.\n\n\nKnoph, Larsen, A. S. 2023. “Novo Nordisk’s Journey to an r Based FDA Submission.” https://www.youtube.com/watch?v=t33dS17QHuA.\n\n\nNeitman, Martin, T. 2023. “Shifting to an Open-Source Backbone in Clinical Trials with Roche.” https://www.youtube.com/watch?v=nqJsLSLd39A.\n\n\n“R Consortium Submissions Working Group.” 2021. https://rconsortium.github.io/submissions-wg/.\n\n\nSchuette, P. 2018. “Using r in a Regulatory Environment: Some FDA Perspectives.” https://rinpharma.com/publication/rinpharma_7/.\n\n\nSoukup, M. 2007. “Using r: Perspectives of a FDA Statistical RevieweR.” https://www.r-project.org/conferences/useR-2007/program/presentations/soukup.pdf; useR.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Regulatory Acceptance</span>"
    ]
  },
  {
    "objectID": "art.html",
    "href": "art.html",
    "title": "7  GxP Compliance",
    "section": "",
    "text": "7.1 How do you establish accuracy, reproducibility and traceability?\nFDA definition of validation and GxP compliance means establishing accuracy, reproducibility, and traceability. When working with open source solutions to process and analyze clinical trial data:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#how-do-you-establish-accuracy-reproducibility-and-traceability",
    "href": "art.html#how-do-you-establish-accuracy-reproducibility-and-traceability",
    "title": "7  GxP Compliance",
    "section": "",
    "text": "How do we establish reproducibility of the outputs?\nHow do we establish traceability of the input through to the output?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#are-we-validating-r-packages-or-the-r-environment",
    "href": "art.html#are-we-validating-r-packages-or-the-r-environment",
    "title": "7  GxP Compliance",
    "section": "7.2 Are we validating R packages or the R environment?",
    "text": "7.2 Are we validating R packages or the R environment?\nWhen discussing R validation, most of the discussion centres around validation of R functions and packages individually. Do they give the “right” or “expected” answer within a defined tolerability / accuracy? Can we trust the developers of the packages that they have adequately tested and documented all aspects of their package? Are there some packages that don’t need validation?\nUsing the FDA definition of “validation” - establishing accuracy, reproducibility and traceability - the accuracy part is only one piece of the puzzle. The ability to get this accurate answer every time, and often over a period of years (so maintaining a validated environment) is also a critical part. It is not unknown for regulatory agencies to request re-analysis or extension of analysis to additional data many years after a regulatory submission. In that event it may be expedient to be able to reuse the environment from the original analysis, rather than trying to replicate the old analysis in a new environment, with new versions of software and packages.\nWith that in mind, having a validated environment, tested and held under change control and able to reproduce results for many years to come would seem like an important aspect of the FDA validation definition. But this raises some interesting questions and problems: how do we maintain a “snapshot” of that environment such that it will be reproducible for years, when operating systems and underlying core software changes more frequently? How do we balance the need for stability and change control with the desire from scientists to have “latest and greatest” packages and versions of packages in order to be most efficient and do the best science? Can both of these states be possible?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#r-validation-hub-and-riskmetric",
    "href": "art.html#r-validation-hub-and-riskmetric",
    "title": "7  GxP Compliance",
    "section": "7.3 R Validation Hub and \\{riskmetric\\}",
    "text": "7.3 R Validation Hub and \\{riskmetric\\}\nThe R Consortium R Validation Hub Working Group have prepared a white paper on R validation, what it means from a package and environment perspective. They propose a risk-based approach where a package’s risk is based on a collection of metrics such as\n\ntesting and documentation\nactive development and contribution\nmaintenance and release cycles\nusage and licensing\n\nThe {riskmetric} package (R Validation Hub et al. (2024)) has been developed to help collect these metrics for packages on CRAN or Github and an associated Shiny application {riskassessment} (Clark et al. (2023)) has been developed.\nThe risk-based approach passes the assessment back to individual organisations. A package may be considered “high risk” but may also be business critical for delivery in a given part of the organisation. So instead of defining a cutoff above which packages would be “not recommended” the R Validation Hub and {riskmetric} are encouraging organisations (and individuals) to give it consideration and perhaps focus effort and resources on assessing and testing packages that are medium to higher risk, rather than those with lower risk.\n\n7.3.1 Testing\nModern package development processes (Wickham and Bryan 2023) encourage the use of test cases to demonstrate that functions within the package are performing as expected. Tools such as {covr} (Hester 2023) examines the test cases within a package and reports the test coverage - what proportion of functions within the package have associated tests - which can be used as a metric to what extent the package developer has assessed that functions within the package work as expected (and fail when appropriate). The associated {covtracer} (Kelkhoff and McNeil 2024) package uses {covr} to identify which functions do or do not have associated tests. These packages help build a picture of how thoroughly tested functions and packages are.\nWhile not mandatory for submission to CRAN, this good practice of providing test cases and verifying function behaviour and performance goes a long way to satisfying the validation requirement of accuracy, and, because these tests are run as part of building the R package for inclusion in CRAN, they will be tested across many different operating systems, versions of R, and compatibility with other CRAN packages they may rely on. With this in mind, the question arises: If a package has good test coverage and tests key or critical functions within the package adequately, and if the package is tested via CRAN build across a range of operating systems, is it really necessary to build new tests and verify internal to an organisation that said package does what it is purported to do?\nIf a package has low test coverage, or if key functions are not tested adequately, then what do we do? Rather than each organisation write new tests, in the spirit of open-source development, surely the correct thing to do is to contribute new tests to the package for the benefit of the broader user community.\n\n\n7.3.2 Documentation\nA key attribute (and expecation) of an R package is that functions accessible to users should be adequately documented. In the past, this was done by the user writing .Rd manual files. Today, tools such as {roxygen2} (Wickham et al. 2024) and {pkgdown} (Wickham, Hesselberth, and Salmon 2023) take a lot of burden from the user and elegant documentation and associated web pages can be built with very little additional effort on the developer. Tools within Integrated Development Environments such as RStudio IDE (RStudio Team 2020) can assist the developer in creating the {roxygen2} header based on inputs to the function being written. With these frameworks it is easier than ever to provide quality documentation for functions and packages. Documentation is not on the FDA list of validation attributes, but it could be argued that without good documentation, the user could easily use functions inappropriately, leading to poor accuracy of results.\n\n\n7.3.3 Active contribution, maintenance and release cycles\nThe R Validation Hub {riskmetric} package also assesses whether packages are actively maintained - whether the package has a named maintainer, whether bug reports are being actioned and closed, whether there is a NEWS file and other attributes. This gives a picture of whether the package is actively maintained by the developer / maintainer. Inactive packages increase the associated risk for organisations. If a bug is reported, but not actioned and the community not made aware of the bug, then this is a bad sign for a package. There could be many reasons that a package is no longer maintained - if it works exactly as advertised and has a very limited scope then perhaps it does not need active maintenance, and it may not need new releases. But this should be flagged for the user and their organisation to assess.\n\n\n7.3.4 Licensing and usage\nPackages made open-source should have an associated license. This details liability from the developer’s and user’s standpoint, scope of use and any limitations, stipulations or expectations around whether modifications of the source code must also be shared publically. It is the user’s responsibility to check whether the license permits them to use and / or modify the package in their intended way. Obviously at an organisation level, it may be beneficical to flag any packages with non-permissive licenses. {riskmetric} helps with that process.\nThe number of downloads of a package gives some indication of the user base of that package globally. While this doesn’t guarantee quality by any means, it does give a measure of how many people are using and interacting with the package and its functions. If the number is large, then an organisation might feel comfortable that issues or errors will be discovered quickly, and that remediation might be also be addressed promptly. If the number is small, then an organisation might wish to examine the package more carefully. This, coupled with a single maintainer, low levels of maintenance, or low test coverage may be a red flag that any issues will be addressed and so risk is increased.\n\n\n7.3.5 CRAN\nWhen a package is submitted to the Comprehensive R Archive Network (CRAN), there are a number of checks and assessments performed on a package before it is made available through the CRAN mirrors for download and installation. Many of the checks are automated, but the results of the checks are assessed manually and often actions are sent by the CRAN team back to the developer to remedy. The CRAN team also check many of the attributes given above - documentation, maintainer, successful tests etc.\nPackages on CRAN are also assessed for compatibility with other packages on CRAN. Any dependencies, reverse dependencies (packages that depend on the submitted package), are assessed so that we can be sure that packages on CRAN work together as expected. This reduces uncertainty greatly, since any given daily snapshot of CRAN is guaranteed to work with conflicts.\nThis level of testing and rigour should not be taken for granted. The CRAN team ensures quality in the package set made available across CRAN mirrors globally for millions of R users.\nWith this, having a package available on CRAN elevates its quality (or lowers its risk) but not to zero.\n\n\n7.3.6 Tidyverse / Posit packages\nPosit / RStudio PBC issued a statement regarding validation of their {tidyverse}, {tidymodels} and {gt} packages and their r-lib Github organisations in 2020 (“Tidyverse, Tidymodels, r-Lib, and Gt r Packages: Regulatory Compliance and Validation Issues” 2020). In it they detail how the packages listed have verifiable software development life-cycle and meet the attributes defined by the R Validation Hub for low risk packages.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#r-package-management---the-problem",
    "href": "art.html#r-package-management---the-problem",
    "title": "7  GxP Compliance",
    "section": "7.4 R package management - the problem",
    "text": "7.4 R package management - the problem\nWe have discussed above how each CRAN daily snapshot ensures that packages from that snapshot date are guaranteed to together through the CRAN checks and CRAN team oversight. To address the validation requirement of reproducibility and traceability, the obvious answer would be to pick a snapshot date for CRAN packages and commit an R environment to that date, locking the package versions to that snapshot date, testing, documenting and holding it under change control from that point. We would then be able to report the R version, CRAN snapshot date resulting in R package versions for that nominated date. This would enable any third party to recreate our environment and reproduce any analysis done with that environment. All we need is to stick with one snapshot date per release of R. Is that viable?\nBut what happens if a user downloads a new package from any other source outside of that snapshot date? If that package has dependencies that are now updated, then the installation process will likely download the updated dependencies. Do we know exactly what has been updated and when? Can we rely on reproducibility for this new set? If the user has kept careful note of exactly what has updated, what packages and versions are now being used, then maybe.\nAnd over a period of months and years, as users update packages, add new ones, as packages stop being updated and functionality is superceded by other packages, how can we guarantee that at any given time we can “roll back” to our validated set and reproduce results?\nThe tension comes because there are two competing priorities:\n\nhaving a set of packages under a well-managed, change controlled, tested and documented environment.\nbeing flexible enough to update packages, versions at an arbitrary time in order to get the latest, greatest features and functionality to address today’s work.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#r-package-management---possible-solutions",
    "href": "art.html#r-package-management---possible-solutions",
    "title": "7  GxP Compliance",
    "section": "7.5 R package management - possible solutions",
    "text": "7.5 R package management - possible solutions\nAt an organisation level, we can use containerisation technologies like Podman or Docker to capture a complete R environment including underlying operating system, base R, and R packages. This will snapshot the complete environment and ensure reproducibility for the long term, as we can return to the container at any point (provided it is held under change control), deploy it and reproduce a given analysis at an arbitrary point in time. Because of the effort required to build, test, document and deploy the environment however, we can’t do this on a daily basis (or for every CRAN snapshot date). Instead we may wish to do this periodically - for example with each R minor release e.g. R-4.2, R-4.3. This approach well serves the first priority above - a well-managed, change controlled, tested and documented environment.\nBut that does not address the second priority above - requiring a flexible environment where users can get the latest and greatest set of packages.\nTo address this need, we would need to turn to R package environment management tools like {renv}. {renv} works in the context of a project and creates a self-contained cache of R packages within the project so that all packages required for the project are kept alongside the project work. This is ideal for most cases where the managed container doesn’t contain all packages required for a project. However it relies on the project owner to maintain this package set and to qualify and document the package set used.\nFor both approaches, we need a single source of R packages that allows users to “go back in time” to any given snapshot date in order to recreate the state of the R environment used in the project or analysis. Posit provides Package Manager . This provides a snapshot of CRAN across various dates and unique URLs for users to define the specific repository used to access R packages on that snapshot date. Previously Microsoft R Archive Network (MRAN) provided similar functionality, but unfortunately this service is no longer maintained.\nWhile the functionality above provides a means for individuals to instantiate and maintain a reproducible R environment complete with arbitrary packages needed for a specific analysis, it relies on individuals to appropriately document and maintain that environment. The barrier to doing it is lowered, but the discipline involved in capturing details of the environment and then managing it for the longer term becomes higher than the change controlled container environment, which may be done at the organisational level, rather than the individual level. It’s also almost impossible to retrofit the documentation and R package management environment. Who knows whether the environment actually used in the analysis entirely matches the defined package set and local environment presented?\nThe other issue is that only a minority of analysts are careful enough to manage their environment to this level. And for a “validated environment” for regulatory use, the level of information required to completely reproduce the environment is quite substantial. Are we confident that we have provided sufficient information for agency staff to do so?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#traceability---where-is-the-r-log",
    "href": "art.html#traceability---where-is-the-r-log",
    "title": "7  GxP Compliance",
    "section": "7.6 Traceability - Where is the R log?",
    "text": "7.6 Traceability - Where is the R log?\nMany tools are available then to help document what R environment was used for the analysis, and many of these are easily accessible if the analyst chooses to use them.\n{sessioninfo} provides information about what packages were loaded within the current R session, what underlying operating system was in use, what R version, what R packages and versions and where those R packages were installed from. This is the minimal information that should be provided for any analysis performed with R. Combined with package management tools like Posit Package Manager or CRAN, this information will allow a good attempt at recreating the environment.\nA {renv} lock file is a similar tool that would allow a third party to recreate the R environment used in analysis, and it contains the URL of repositories used to install packages. Provided the URLs are accessible to the third party, it should provide additional confidence in the ability to recreate the environment.\nThe {logrx} package aims to go another step in providing additional metadata, user, session and run time information. By providing a wrapper for running an R script, it also prevents the possibility of users running commands interactively out of sequence, or picking objects from the Global Environment inside R instead of re-calculating.\nThis list is not exhaustive by any means, but each tool gives additional information that would assist forensic recreation of the R environment at an arbitrary time point. They do not magically recreate the R environment, only document what was used.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#the-ideal-solution",
    "href": "art.html#the-ideal-solution",
    "title": "7  GxP Compliance",
    "section": "7.7 The ideal solution",
    "text": "7.7 The ideal solution\nThe best solution is to combine a tool such as {logrx} with a well managed container environment deployment of R as described above. This proves that the container was unchanged from the original, tested and documented environment. And assuming that original container is held under Software Development Life Cycle change control, we can be confident of accuracy, reproducibility and traceability, and hence a “validated” environment.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "art.html#discussion",
    "href": "art.html#discussion",
    "title": "7  GxP Compliance",
    "section": "7.8 Discussion",
    "text": "7.8 Discussion\nContribute to the discussion here in GitHub Discussions:\nHow do you establish reproducibility and traceability with open source solutions?\n\n\n\n\nClark, Aaron, Robert Krajcik, Jeff Thompson, Lars Andersen, Andrew Borgman, Marly Gotti, Maya Gans, Aravind Reddy Kallem, and Fission Labs India Pvt Ltd. 2023. Riskassessment: A Web App Designed to Interface with the ‘Riskmetric‘ Package. https://github.com/pharmaR/riskassessment.\n\n\nHester, Jim. 2023. Covr: Test Coverage for Packages. https://covr.r-lib.org.\n\n\nKelkhoff, Doug, and Andrew McNeil. 2024. Covtracer: Tools for Contextualizing Tests. https://github.com/genentech/covtracer.\n\n\nR Validation Hub, Doug Kelkhoff, Marly Gotti, Eli Miller, Kevin K, Yilong Zhang, Eric Milliman, and Juliane Manitz. 2024. Riskmetric: Risk Metrics to Evaluating r Packages. https://pharmar.github.io/riskmetric/.\n\n\nRStudio Team. 2020. RStudio: Integrated Development Environment for r. Boston, MA: RStudio, PBC. http://www.rstudio.com/.\n\n\n“Tidyverse, Tidymodels, r-Lib, and Gt r Packages: Regulatory Compliance and Validation Issues.” 2020. Posit / RStudio PBC. https://www.rstudio.com/assets/img/validation-tidy.pdf.\n\n\nWickham, Hadley, and Jenny Bryan. 2023. R Packages. O’Reilly Media, Incorporated.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster. 2024. Roxygen2: In-Line Documentation for r. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, and Maëlle Salmon. 2023. Pkgdown: Make Static HTML Documentation for a Package. https://pkgdown.r-lib.org.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>GxP Compliance</span>"
    ]
  },
  {
    "objectID": "users.html",
    "href": "users.html",
    "title": "8  (-) User Support",
    "section": "",
    "text": "8.1 How do we support users in managing an ever-evolving environment of Open Source solutions?\nThe conventional user (programmer) processing clinical trial data may be used to stability of the available toolbox at their disposal.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>(-) User Support</span>"
    ]
  },
  {
    "objectID": "users.html#how-do-we-support-users-in-managing-an-ever-evolving-environment-of-open-source-solutions",
    "href": "users.html#how-do-we-support-users-in-managing-an-ever-evolving-environment-of-open-source-solutions",
    "title": "8  (-) User Support",
    "section": "",
    "text": "How can we help users to operate in a (potentially) more variable environment?\nHow can we help users to address unexpected challenges due to changes in their computational environment?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>(-) User Support</span>"
    ]
  },
  {
    "objectID": "users.html#discussion",
    "href": "users.html#discussion",
    "title": "8  (-) User Support",
    "section": "8.2 Discussion",
    "text": "8.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nHow do we support users in managing an ever-evolving environment of Open Source solutions?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>(-) User Support</span>"
    ]
  },
  {
    "objectID": "user_dev.html",
    "href": "user_dev.html",
    "title": "9  (-) User Development",
    "section": "",
    "text": "9.1 How do you transform the traditional Statistical Programmer into the future Data Scientist?\nThe traditional Statistical Programmer/Analyst in pharmaceutical and vaccine development primarily fulfills their role using the SAS programming language to develop single-use scripts that read in data and create an output dataset or analysis display.\nMany Data Scientists are:\nHow will we transform the traditional Statistical Programmer into the future Data Scientist?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>(-) User Development</span>"
    ]
  },
  {
    "objectID": "user_dev.html#how-do-you-transform-the-traditional-statistical-programmer-into-the-future-data-scientist",
    "href": "user_dev.html#how-do-you-transform-the-traditional-statistical-programmer-into-the-future-data-scientist",
    "title": "9  (-) User Development",
    "section": "",
    "text": "programmatically multilingual\nleverage open source tools\nare familiar with object-oriented languages\ndevelop code collaboratively with platforms such as GitHub\nversion control code with technologies such as git\nare comfortable having code reviewed for functionality and good programming practice\nare familiar with good software development practices\nare familiar and comfortable with agile ways of working",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>(-) User Development</span>"
    ]
  },
  {
    "objectID": "user_dev.html#discussion",
    "href": "user_dev.html#discussion",
    "title": "9  (-) User Development",
    "section": "9.2 Discussion",
    "text": "9.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nHow do you transform the traditional Statistical Programmer into the future Data Scientist?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>(-) User Development</span>"
    ]
  },
  {
    "objectID": "match.html",
    "href": "match.html",
    "title": "10  Numerical Matching",
    "section": "",
    "text": "10.1 What if open source languages and commercial software (such as SAS), do not match numerically with the analysis results they give?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#what-if-open-source-languages-and-commercial-software-such-as-sas-do-not-match-numerically-with-the-analysis-results-they-give",
    "href": "match.html#what-if-open-source-languages-and-commercial-software-such-as-sas-do-not-match-numerically-with-the-analysis-results-they-give",
    "title": "10  Numerical Matching",
    "section": "",
    "text": "What if the same inputs yield similar, but numerically different results?\nWhat if the same inputs yield drastically different results?\nWhat is the truth? Which is correct? Can any be considered ‘correct’?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#historical-background",
    "href": "match.html#historical-background",
    "title": "10  Numerical Matching",
    "section": "10.2 Historical Background",
    "text": "10.2 Historical Background\nThe statistical analysis system SAS was developed by a collective of eight USA southern state universities in the late 1960’s. The SAS Institute Inc. was founded in 1976, and their first product release of Base SAS, consisted of approximately 300,000 lines of code1. During the first 30 years of existence, SAS software became renowned in the highly regulated medical research industry, for its well documented methodology and its high quality, reproducible, robust and reliable analysis implementation. This made it the number one data analysis tool in the pharmaceutical industry and a gold standard for regulatory submissions around the world.\nR has been available since 1993 with packages being added continuously, providing a continual development cycle and user-led package development2. This open-source language has a package repository called CRAN (Comprehensive R Archive Network) with over 21000 packages in it. The momentum and adoption of R in Pharma is growing, likely due to:\n\nit being a common tool used by students, academics and other industries,\nit’s ability to produce interactive reporting and graphics\nthe large quantity of open source development of packages, which is often conducted through github repositories. Recently, the pharmaverse3 has been created which pulls together multiple packages designed specifically to resolve the needs of conducting analysis in medical research with a focus on the regulatory needs.\n\nIt is commonly found that if the user does not change the default options in SAS and R for a particular analysis, then the results that are output are different! But why is this …?!\nSAS and R would have experienced entirely different challenges during their early development periods. For SAS, latency (speed to do computations) was very low compared to modern computers. The time for a computer to implement a complex statistical analysis (or even a simple one) would have initially been very long! This would have made numerical approximations (faster algorithms) very attractive in order to reduce computational time required to conduct analysis. As computational power improved, the speed to do analysis rapidly improved. The need to simplify an analysis to an approximation or more simple algorithm was less important. Hence SAS increased its functionality adding more methods. However, due to its rigorous reproducibility and backwards compatibility commitments, the ‘default’ method remained as the original, and new methods (which were often more complex) were added as options to the original SAS procedures.\nWith R being developed in the 1990’s, it didn’t have such a restriction on speed of computation. This means that the methods that R defaults to, are often the ones that were most commonly used when that package was developed, or that were documented in the literature with better performance compared to an older methodology.\nIn conclusion, if you write code in SAS and R without specifying fully your analysis using the optional parameters or knowing your default options, it is very likely that the analysis they conduct could be different. In many cases, adding detail to your code (Specifying all options clearly), specifies exactly the analysis you want SAS or R to do, which then ensures that SAS and R are applying the same methods and you get the same results. However, there are still cases where some analyses are only available in SAS and some only in R.\nThe PHUSE CAMIS Project4 compares default analysis methods in SAS, R and Python, documents which options need to be specified in order to obtain a reproduction of the same analysis and identifies cases where software can not replicate the same analysis.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#why-do-we-need-languages-software-to-align-on-results-and-does-it-need-to-be-identical",
    "href": "match.html#why-do-we-need-languages-software-to-align-on-results-and-does-it-need-to-be-identical",
    "title": "10  Numerical Matching",
    "section": "10.3 Why do we need languages / software to align on results and does it need to be identical?",
    "text": "10.3 Why do we need languages / software to align on results and does it need to be identical?\n\n10.3.1 Statistical Interpretation Perspective\nFrom a Statistical Interpretation Perspective, results obtained from different languages or software which are in line (similar) but not identical would be interpreted in the same way. Hence the conclusion of the trial would not be affected by lack of identical replication of statistical analysis results.\nIn fact, it is common for regulators to require sensitivity analysis to explore how robust the analysis is to handling of missing data and model assumptions. Therefore, we would hope that applying slightly different methods, would not change interpretation of the results, otherwise we may have concerns regarding the robustness of our analysis and the transferability of those results to the real world.\nIf results did differ by a clinically important amount, then it would be very important to further investigate and justify the differences.\n\n\n10.3.2 In Practice !\nDespite the above, in practice, the medical research industry is governed by strict processes and Standard Operative Procedures (SOPs) to ensure quality of statistical analysis. For this reason, many companies apply a double programming approach to ensure 100% independent replication of results. This requires a full identical match to be obtained when two programmers do the same work independently. In addition, if the initial work is done by a Contract Research Organization (CRO), working with a pharmaceutical company, the analysis may be programmed a third time to replicate results in the two different companies systems. Finally, when results are submitted to the regulators, they will also program the results and attempt replication.\nTherefore, in all these cases if a full identical match cannot be obtained, this introduces uncertainty, apprehension and nervousness about the results being presented. Are they correct ? ! Why don’t we get the same results doing the same analysis in another language / software.\nIt is likely that the statisticians, data analysts or programmers in all organizations would have to spend substantial time looking into the discrepancy, to try to provide a full explanation and justification, or do updates so a match can be obtained, before the analysis would be passed as acceptable and trustworthy. This is often at a critical time in the drug development program and can adversely affect relationships between customers / clients and regulators, if matches cannot be easily achieved.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#possible-reasons-for-analysis-results-being-different",
    "href": "match.html#possible-reasons-for-analysis-results-being-different",
    "title": "10  Numerical Matching",
    "section": "10.4 Possible Reasons for Analysis Results being Different",
    "text": "10.4 Possible Reasons for Analysis Results being Different\nCommon reasons for not obtaining a match when using different software consist of:\n\nInput dataset differences\n\nCheck your input datasets are identical (different input = different output !)\nNOTE: This may need to also include the sort order since some algorithms may work differently if data is differently sorted\n\nDifferent model or methods used compared to your statistical analysis plan (SAP)\n\nPerhaps the SAP clearly specifies the analysis, however your results is not in line, due to differences in the default options, handling of missing data or tied data, modelling assumptions, method, algorithms, modelling values, convergence methods, optimization routines or parameterization it is using\nCheck the software / package documentation to verify it is doing the analysis method specified in the SAP. NOTE: you may have to do your own research to fully understand how methods are being implemented in software. Replication by hand or in additional programming to see if you can test the results versus what you would expect using the equations. Check on website help pages, StackOverflow etc, to see if others have already found the issue. Contact the software company or author to request clarity on the method the software is implementing.\nCheck PHUSE CAMIS Project4 for any additional detail already available. If you find something not already documented, please consider contributing\nNOTE: sometimes the results may match in most cases, with exception for a particular scenario in your data (small samples, tied data, missing data or thresholds being met), which results in different handling of these cases being made by the software / languages and hence different methods being used and different results obtained.\n\nSAP does not specify enough detail of what analysis is required\n\nSAP is ambiguous - there are different ways to do the analysis method and the SAP does not clearly specify the method that should be applied.\nIt is not sufficient to write a SAP with the SAS defaults being assumed. The method needs to be fully specified such that it can be replicated in any language or software.\nIf the method is not clearly specified in the SAP, default methods may be assumed, and these may be different across software / languages.\nUpdate SAP to be more specific.\n\nSame Methods are being applied but different rounding of the final result. SAS and R round differently by default. See here for more detail.\nThere is a bug is the software / package derivation and the results are incorrect\n\nThis is the least commonly found issue when renown software and packages are being used. It is more common that the method being implemented is actually planned by the software / package authors to be different, rather than incorrectly programmed.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#best-practice-steps",
    "href": "match.html#best-practice-steps",
    "title": "10  Numerical Matching",
    "section": "10.5 Best practice steps",
    "text": "10.5 Best practice steps\nThe White paper5 describes key considerations when understanding differences in statistical methodology implementations across programming languages.\nThe Key Message is to ensure that the SAP fully documents the analysis method you plan to do and ensure that the software you use is implementating that analysis method.\nIt is no longer acceptable, to write statistical analysis plans which describe the analysis in insufficient detail, expecting readers to be using the SAS defaults. Instead SAPs need to be written with full explanation of the method being applied, including any detail on convergence methods, continuity corrections applied, and options selected. This can often be challenging since the methodology can be statistically complex and statisticians have got so used to SAS, that there is still a bias towards using the methods that SAS does as default rather than the method which is best for the analysis of your data.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#example-1-signed-rank-test",
    "href": "match.html#example-1-signed-rank-test",
    "title": "10  Numerical Matching",
    "section": "10.6 Example 1 : Signed Rank Test",
    "text": "10.6 Example 1 : Signed Rank Test\nSAP states: For this 2-period, cross-over study comparing Treatments A and B, a wilcoxon signed-rank test will be applied.\nThe analysis is run in SAS and R and slightly different p-values are obtained.\nAfter much research, it is found to be due to the following:\nSAS describes its method here6. For samples &lt;=20 it applies the exact method (scaled binomial distributions). For samples &gt;20 it uses an approximation method using the student’s t distribution. It also has a method for handling of tied data.\nCAMIS repo describe the R options here. Using stats package (version 3.6.2), allows you to specify if you want to use an exact method or normal approximation for any sample size. However there is no method for handling tied data, R excludes these results from the analysis.\nHence for samples without ties and with &lt;20 observations, SAS and R p-values match, however if you do have tied results or &gt;20 observations, it’s likely that you will get slightly different p-values in SAS and R.\nSAP should be updated (for example) to say: For this 2-period, cross-over study comparing Treatments A and B, a wilcoxon signed-rank test using a normal approximation as described in the stats package (version 3.6.2) will be applied.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#example-2-survival-analysis-kaplan-meier-and-log-rank-test",
    "href": "match.html#example-2-survival-analysis-kaplan-meier-and-log-rank-test",
    "title": "10  Numerical Matching",
    "section": "10.7 Example 2: Survival Analysis, Kaplan-Meier and Log Rank Test",
    "text": "10.7 Example 2: Survival Analysis, Kaplan-Meier and Log Rank Test\nSAP states: Kaplan-Meier plots (with 95% CIs) of Overall Survival will be presented by treatment group. Overall survival will be analyzed using a stratified log-rank test with hazard ratio and 95% CI from the cox-proportional hazards model.\nThe analysis is run in SAS and R and although the p-values from the Cox-proportional hazard model are in agreement, we get slightly different confidence intervals on the Kaplan-Meier plots and for the estimate of the Hazard ratio (+/- 95% CIs) estimated from the Cox-proportional hazard model.\nAfter much research, it is found to be due to the following as documented on the CAMIS repository here.\n\nIn SAS, the default Kaplan-Meier confidence interval calculation method is using the log-log method whereas in R package survival::survfit function the default method is the log method.\nIn SAS, the default method for handling of ties in a Cox-propotional hazard model is to use the breslow method, however, in R package survival::coxph , the default method is efron.\n\nBoth of these issues can be resolved but adding options to the code to specify the method. However, the SAP did not specify the methods to use fully enough.\nSAP should be updated (for example) to say: Kaplan-Meier plots (with 95% CIs calculated using the log-log method) of Overall Survival will be presented by treatment group. Overall survival will be analyzed using a stratified log-rank test with hazard ratio and 95% CI from the cox-proportional hazards model calculated using the efron method in the case of tied survival times.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#discussion",
    "href": "match.html#discussion",
    "title": "10  Numerical Matching",
    "section": "10.8 Discussion",
    "text": "10.8 Discussion\nContribute to the discussion here in GitHub Discussions:\nDo we need to match SAS numerically when using a different language?\nContribute to the CAMIS repository here.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "match.html#references",
    "href": "match.html#references",
    "title": "10  Numerical Matching",
    "section": "10.9 References",
    "text": "10.9 References\n\nhttps://www.sas.com/en_us/company-information/history.html\nhttps://royalsocietypublishing.org/doi/10.1098/rsos.221550\nhttps://pharmaverse.org/e2eclinical/\nhttps://psiaims.github.io/CAMIS/\nhttps://phuse.s3.eu-central-1.amazonaws.com/Deliverables/Data+Visualisation+%26+Open+Source+Technology/WP077.pdf\nhttps://support.sas.com/documentation/cdl/en/procstat/63104/HTML/default/viewer.htm#procstat_univariate_sect029.htm",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Numerical Matching</span>"
    ]
  },
  {
    "objectID": "longrun.html",
    "href": "longrun.html",
    "title": "11  (-) OS in the Long Run",
    "section": "",
    "text": "11.1 How do we ensure that the solutions being developed today will exist in the long run?\nWhen these solutions are embedded in data pipelines, if development and maintenance support disappears, there is a risk to the pipelines which leverage them.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>(-) OS in the Long Run</span>"
    ]
  },
  {
    "objectID": "longrun.html#how-do-we-ensure-that-the-solutions-being-developed-today-will-exist-in-the-long-run",
    "href": "longrun.html#how-do-we-ensure-that-the-solutions-being-developed-today-will-exist-in-the-long-run",
    "title": "11  (-) OS in the Long Run",
    "section": "",
    "text": "How do we ensure long term viability?\nHow do we ensure long term sustainability?\nHow do we ensure long term maintainability?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>(-) OS in the Long Run</span>"
    ]
  },
  {
    "objectID": "longrun.html#discussion",
    "href": "longrun.html#discussion",
    "title": "11  (-) OS in the Long Run",
    "section": "11.2 Discussion",
    "text": "11.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nHow do we ensure that the solutions being developed today will exist in the long run?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>(-) OS in the Long Run</span>"
    ]
  },
  {
    "objectID": "fundOS.html",
    "href": "fundOS.html",
    "title": "12  (-) Funding OS",
    "section": "",
    "text": "12.1 Is it possible for industry fund open source?",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>(-) Funding OS</span>"
    ]
  },
  {
    "objectID": "fundOS.html#is-it-possible-for-industry-fund-open-source",
    "href": "fundOS.html#is-it-possible-for-industry-fund-open-source",
    "title": "12  (-) Funding OS",
    "section": "",
    "text": "Is it possible to fund OS development in pharmaceutical drug and vaccine development?\nWhat might a funding model look like?\nWhat problem(s) would funding solve?\nAre there examples of this in other industries?",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>(-) Funding OS</span>"
    ]
  },
  {
    "objectID": "fundOS.html#discussion",
    "href": "fundOS.html#discussion",
    "title": "12  (-) Funding OS",
    "section": "12.2 Discussion",
    "text": "12.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nIs it possible for industry fund open source?",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>(-) Funding OS</span>"
    ]
  },
  {
    "objectID": "liability.html",
    "href": "liability.html",
    "title": "13  Liability with OS",
    "section": "",
    "text": "13.1 Are contributors to open source exposing themselves to any liability of their solutions?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Liability with OS</span>"
    ]
  },
  {
    "objectID": "liability.html#are-contributors-to-open-source-exposing-themselves-to-any-liability-of-their-solutions",
    "href": "liability.html#are-contributors-to-open-source-exposing-themselves-to-any-liability-of-their-solutions",
    "title": "13  Liability with OS",
    "section": "",
    "text": "What are possible sources of liabilities?\nAre there mitigating actions which can limit or eliminate liabilities?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Liability with OS</span>"
    ]
  },
  {
    "objectID": "liability.html#understanding-liability-and-warranty-in-software-development",
    "href": "liability.html#understanding-liability-and-warranty-in-software-development",
    "title": "13  Liability with OS",
    "section": "13.2 Understanding Liability and Warranty in Software Development",
    "text": "13.2 Understanding Liability and Warranty in Software Development\nLiability and warranty are two crucial legal concepts in the realm of software development. Liability refers to the legal obligation or responsibility that arises from actions or lack thereof. In the context of software, this could mean the responsibility for any system malfunctions, data breaches, or data loss that occur due to the software.\nOn the other hand, a warranty is a pledge or assurance given by the provider of the source code. It’s a promise that the software will perform as described and that any defects or issues will be addressed within a specified period.\nGiven the potential risks associated with software use, such as system malfunctions or data breaches, the liability and warranty of the source code provider become critical considerations.\nMost open-source licenses include a disclaimer to shield developers from claims. However, the responsibility for liability and warranty doesn’t solely rest with open-source users, either. It extends to all software users, including those using commercial software.\nAndy Nicholls has helpfully provided a link to the EMA’s Notice on validation and qualification of software tools used in clinical trials. This document clearly states that the sponsor bears the ultimate responsibility for the validation of the computerised system. They must provide adequate documented evidence of the validation process.\nWhile the sponsor can rely on qualification documentation provided by the vendor, they must assess the adequacy of the vendor’s qualification activities. Based on a documented risk assessment, the sponsor may also need to perform additional qualification and validation activities.\n\nThe sponsor is ultimately responsible for the validation of the computerised system and for providing adequate documented evidence on the validation process. […] The sponsor may rely on qualification documentation provided by the vendor, if the qualification activities performed by the vendor have been assessed as adequate. However, the sponsor may also have to perform additional qualification (and validation) activities based on a documented risk assessment.\n\nSummary: Regardless of whether open-source or commercial software is used, the sponsor carries the responsibility for warranty and liability. While commercial software requires reliance on the vendor, the transparency of open-source software offers additional avenues for assurance and accountability.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Liability with OS</span>"
    ]
  },
  {
    "objectID": "liability.html#liability-and-warranty-according-open-source-licenses",
    "href": "liability.html#liability-and-warranty-according-open-source-licenses",
    "title": "13  Liability with OS",
    "section": "13.3 Liability and Warranty according Open Source Licenses",
    "text": "13.3 Liability and Warranty according Open Source Licenses\nMost open source licenses include a disclaimer of liability and warranty. So according the license there is no liability and warranty from the source code provider.\nExamples:\n\nMIT License\n\nThe software is provided “as is”, without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.\n\nApache License 2.0\n\n\nDisclaimer of Warranty  Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\nLimitation of Liability In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.\n\nAccepting Warranty or Additional Liability While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.\n\n\nGNU General Public License v3.0\n\n\nDisclaimer of warranty. There is no warranty for the program, to the extent permitted by applicable law. Except when otherwise stated in writing the copyright holders and/or other parties provide the program “as is” without warranty of any kind, either expressed or implied, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose. The entire risk as to the quality and performance of the program is with you. Should the program prove defective, you assume the cost of all necessary servicing, repair or correction.\nLimitation of liability. In no event unless required by applicable law or agreed to in writing will any copyright holder, or any other party who modifies and/or conveys the program as permitted above, be liable to you for damages, including any general, special, incidental or consequential damages arising out of the use or inability to use the program (including but not limited to loss of data or data being rendered inaccurate or losses sustained by you or third parties or a failure of the program to operate with any other programs), even if such holder or other party has been advised of the possibility of such damages.\n\n\nBSD 3-Clause “New” or “Revised” License\n\nThis software is provided by the copyright holders and contributors “as is” and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. In no event shall the copyright holder or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Liability with OS</span>"
    ]
  },
  {
    "objectID": "liability.html#discussion",
    "href": "liability.html#discussion",
    "title": "13  Liability with OS",
    "section": "13.4 Discussion",
    "text": "13.4 Discussion\nContribute to the discussion here in GitHub Discussions:\nAre contributors to open source exposing themselves to any liability of their solutions?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Liability with OS</span>"
    ]
  },
  {
    "objectID": "legal.html",
    "href": "legal.html",
    "title": "14  Legal Concerns",
    "section": "",
    "text": "14.1 Are there any legal concerns from open source development?",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#are-there-any-legal-concerns-from-open-source-development",
    "href": "legal.html#are-there-any-legal-concerns-from-open-source-development",
    "title": "14  Legal Concerns",
    "section": "",
    "text": "What do individuals need to know?\nWhat do organizations need to know?\nHow does this differ if the solution is an individual or a collaborative effort?",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#understanding-legal-concerns",
    "href": "legal.html#understanding-legal-concerns",
    "title": "14  Legal Concerns",
    "section": "14.2 Understanding Legal Concerns",
    "text": "14.2 Understanding Legal Concerns\nIn our world today, where claims are frequently made, it’s clear that many of us have concerns about the potential legal issues tied to open source development. Whether we’re contributing as individuals or as part of an organization, we all have a role to play. It’s only natural and indeed obvious that we might feel unsure or anxious about possible missteps. However, by deepening our understanding of these legal concerns, we can navigate this space with greater confidence, mitigate risks, and avoid potential claims.\nThis involves being aware of the terms of open source licenses, understanding how to comply with them, and knowing how to properly attribute open source contributions.\n\n14.2.1 What Individuals Need to Know\nAs an individual contributing to open source projects, you should be aware of the licenses under which your contributions will be distributed. Different open source licenses have different requirements and restrictions. Failing to comply with them can lead to legal issues. Therefore, before contributing to any open source project, make sure to:\n\nUnderstand the terms of the license under which your contribution will be distributed.\nEnsure your contributions do not infringe upon someone else’s intellectual property.\nRespect Your Employer’s Intellectual Property Rights.\nKeep a record of your contributions for future reference.\n\nExamples\nAs a user, creator, or contributor of open source software, you have responsibilities to understand and respect the licenses of the software you interact with. Here are a few key points:\n\nUnderstand the terms of the license of the software you are using.\nFor example, if you’re using software licensed under the GNU General Public License (GPL), you should know that you are free to use, modify, and distribute the software, but any derivative work must also be distributed under the GPL. If you’re using software under the MIT license, you can use it for any purpose, even commercial ones, but you must include the original copyright notice.\nEnsure your use of the software does not infringe upon the software’s license.\nThis means that you should use the software in a way that complies with its license. For instance, if the software is licensed under the GPL, and you modify it and distribute the modified version, you must also distribute the source code of your modified version under the GPL.\nAdditionally, it’s important to remember that this principle applies to all code you incorporate into your project, not just the original software. If you copy code from another source, such as a Stack Overflow answer, you must respect the license of that code as well. For example, code posted in Stack Overflow answers is licensed under a Creative Commons Attribution-ShareAlike license (CC BY-SA). This means that you can use and modify the code, but you must give appropriate credit and distribute any modifications under the same license. Ignoring these requirements can lead to legal issues.\nRespect Your Employer’s Intellectual Property Rights\nIf you’re contributing to open source projects as part of your job, it’s important to remember that the code you write for your employer is likely their intellectual property. This means that you can’t just take code you’ve written for them and contribute it to an open source project without their permission.\nHowever, this doesn’t mean that you can’t contribute at all. If you’ve developed a useful piece of code for your job and you think it could benefit the open source community, consider reprogramming it in your free time. This way, you’re not directly using your employer’s code, but you’re still able to contribute your ideas and skills to the project.\nAlways check your employment contract and consult with your employer or a legal professional if you’re unsure about what you can and can’t do. Ignoring these requirements can lead to legal issues, including potential job loss or lawsuits.\nKeep a record of the software you use and their licenses for future reference.\nThis could be as simple as maintaining a list of the software you use and their licenses, or using a software composition analysis tool, which can automatically detect the licenses of the software you use. This can help you ensure that you are complying with all the licenses and avoid potential legal issues.\n\nTips for Individuals\nAs an individual working with open-source software, here are some tips to help you navigate the legal landscape:\n\nAlways Check for a License: Before using, modifying, or contributing to an open-source project, always check for a license. The license will tell you what you can and cannot do with the source code.\nPrefer Permissive Licenses: If you have a choice, prefer software with permissive licenses like MIT or Apache. These licenses allow you to use, modify, and distribute the software with fewer restrictions.\nRewrite Instead of Copy: Especially for smaller code snippets, consider rewriting the code in your own words instead of copying it directly. This can help you avoid potential licensing issues.\nMaintain a List of Used Open-Source Software: Keep a list of all open-source code that you use or incorporate into your projects. Include a copy of their licenses and any attribution notices. This can help you ensure that you are complying with all licenses and avoid potential legal issues.\n\n\n\n14.2.2 What Organizations Need to Know\nOrganizations using or contributing to open source projects ideally should maintain a clear open source policy. This policy should outline how to handle open source licenses, how to contribute to open source projects, and how to use open source software in a way that complies with the respective licenses. To mitigate risks and avoid potential claims, organizations should:\n\nDevelop a comprehensive open source policy and ensure all members understand it.\nRegularly review and update the policy to keep it in line with current legal standards.\nUse tools to track the use of open source software and ensure compliance with their licenses.\nSeek legal advice when necessary.\n\nBy deepening our understanding of these legal concerns, we can all contribute to the open source community in a way that respects the rights of all parties involved.\n\n\n14.2.3 Different Risks to Individuals and Organizations\nThe legal risks associated with open source development can vary for individuals and organizations due to the nature of their involvement and the scale of their operations.\nAs an individual contributor, you might face the following risks:\n\nLicense Violations: If you contribute to a project without fully understanding the terms of its license, you might inadvertently violate it. This could potentially lead to legal action from the project owner or other contributors.\nIntellectual Property Infringement: If your contributions to an open source project infringe upon someone else’s intellectual property, you could face legal consequences. This could happen if you contribute code that you don’t have the rights to or that is covered by a proprietary license.\nPersonal Liability: In some cases, you could be held personally liable for issues with your contributions, such as security vulnerabilities or bugs that cause damage to users.\n\nOrganizations face similar risks to individuals but on a larger scale. Additional risks include:\n\nReputation Damage: If an organization is found to have violated an open source license or infringed upon someone else’s intellectual property, it could suffer significant damage to its reputation.\nOperational Disruptions: Legal issues related to open source software could lead to operational disruptions. For example, if an organization is found to be using open source software in violation of its license, it might be required to stop using that software, which could disrupt its operations.\nFinancial Losses: Legal issues can lead to financial losses due to legal fees, fines, or the costs associated with operational disruptions.\n\nBy understanding these risks and taking steps to mitigate them, both individuals and organizations can contribute to open source projects in a way that minimizes their legal exposure.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#legal-practicalities",
    "href": "legal.html#legal-practicalities",
    "title": "14  Legal Concerns",
    "section": "14.3 Legal Practicalities",
    "text": "14.3 Legal Practicalities\nIt’s crucial to understand that everything written down, including texts, images, and source code, is protected by copyright. This applies unless there’s an explicit license attached to the material. This means we are not permitted to copy source code from papers, blogs, or forums unless a license is provided. Using copyrighted code could potentially lead to legal action. However, we can learn from what we read and re-implement the source code. We are always free to take an idea and reprogram it.\nIf you wish to facilitate the usage of your source code, remember to apply a license. For instance, the “Unlicense” or “Public Domain” license allows unrestricted use, while the “MIT” license requires that you are credited in any derivative works. Apply a license when you include source code in papers, blogs, forums, or any documentation. Without a license, it’s legally risky to use your source code.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#additional-insights",
    "href": "legal.html#additional-insights",
    "title": "14  Legal Concerns",
    "section": "14.4 Additional Insights",
    "text": "14.4 Additional Insights\n\n14.4.1 Contributor License Agreements\nFor organizations, managing internal contributions to open-source projects can be streamlined with appropriate training. This ensures that employees understand what can and cannot be included in open-source contributions. However, a common concern arises with external contributors.\nIt’s crucial to ensure that no unauthorized code is incorporated into the solution. In theory, when individuals submit changes, for instance, via GitHub, they agree to abide by the repository’s license.\nTo further safeguard the project, organizations could consider implementing a formal Contributor License Agreement (CLA). This agreement provides a clear understanding that contributors relinquish (and simultaneously regain) the rights to their contributed source code. It also ensures that they do not include any proprietary secrets or unshareable source code. Implementing a CLA adds an extra layer of legal protection for both the project and its contributors.\n\n\n14.4.2 Cyber Resilience Act\nAnother topic brought up by James Black is the “Cyber Resilience Act”. The EU Cyber Resilience Act is a significant piece of legislation that will introduce new responsibilities specifically for organizations and companies providing open-source software. This act aims to enhance the overall cybersecurity posture of the digital ecosystem by establishing a robust framework for managing cyber risks.\nFor open-source providers, this could mean implementing more stringent security measures, conducting regular vulnerability assessments, and ensuring timely patching and updates. It may also necessitate greater transparency about their security practices and more rigorous reporting of security incidents.\nWhile the specifics of the act are still being finalized, it’s clear that it will have far-reaching implications for the open-source community. Organizations and companies involved in open-source should closely monitor the development of this legislation and start preparing for its potential impact.\nFor single-individual open-source projects, the impact might be less direct. However, it could still influence the way these projects are managed. For instance, the act might encourage individual developers to adopt more robust security practices, such as conducting regular vulnerability assessments and ensuring timely patching and updates.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#resources-and-links",
    "href": "legal.html#resources-and-links",
    "title": "14  Legal Concerns",
    "section": "14.5 Resources and Links",
    "text": "14.5 Resources and Links\n\nOpen Source Initiative - Definition & Overview of Licenses - https://opensource.org/\nChoose a License - Overview of commonly used licenses - https://choosealicense.com/licenses/\nPresentation video - “Open Source Licenses - Practicalities and the Legal Side” - https://youtu.be/6CtoH2yZb-I\nCyber Resilience Act - https://www.european-cyber-resilience-act.com/",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "legal.html#discussion",
    "href": "legal.html#discussion",
    "title": "14  Legal Concerns",
    "section": "14.6 Discussion",
    "text": "14.6 Discussion\nContribute to the discussion here in GitHub Discussions:\nAre there any legal concerns or ramifications from open source development (on the user, developer, organization)?",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Legal Concerns</span>"
    ]
  },
  {
    "objectID": "OSmodels.html",
    "href": "OSmodels.html",
    "title": "15  (-) OS Business Models",
    "section": "",
    "text": "15.1 What open source models are available for businesses?",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>(-) OS Business Models</span>"
    ]
  },
  {
    "objectID": "OSmodels.html#what-open-source-models-are-available-for-businesses",
    "href": "OSmodels.html#what-open-source-models-are-available-for-businesses",
    "title": "15  (-) OS Business Models",
    "section": "",
    "text": "How to address the challenge of making money providing software that is, by definition, licensed free of charge?\nWhat is open core?\nWikipedia page",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>(-) OS Business Models</span>"
    ]
  },
  {
    "objectID": "OSmodels.html#discussion",
    "href": "OSmodels.html#discussion",
    "title": "15  (-) OS Business Models",
    "section": "15.2 Discussion",
    "text": "15.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nWhat open source models are available for businesses?",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>(-) OS Business Models</span>"
    ]
  },
  {
    "objectID": "whatelse.html",
    "href": "whatelse.html",
    "title": "16  (-) What Else?",
    "section": "",
    "text": "16.1 What else can we do?\nThis is very open ended and initially intended as a catch-all for the future considerations not already covered by the other discussions.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>(-) What Else?</span>"
    ]
  },
  {
    "objectID": "whatelse.html#what-else-can-we-do",
    "href": "whatelse.html#what-else-can-we-do",
    "title": "16  (-) What Else?",
    "section": "",
    "text": "What have we missed?\nWhat other questions are being asked and/or need to be addressed?",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>(-) What Else?</span>"
    ]
  },
  {
    "objectID": "whatelse.html#discussion",
    "href": "whatelse.html#discussion",
    "title": "16  (-) What Else?",
    "section": "16.2 Discussion",
    "text": "16.2 Discussion\nContribute to the discussion here in GitHub Discussions:\nWhat else can we do?",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>(-) What Else?</span>"
    ]
  },
  {
    "objectID": "contribute.html",
    "href": "contribute.html",
    "title": "Contribute",
    "section": "",
    "text": "Join discussions\nShare your industry expertise and contribute to the collective knowledge by joining our discussions. These discussions are a valuable resource, providing citable and sometimes quotable input that will culminate in a “state of the union”-style manuscript. This manuscript aims to address questions that have been sufficiently explored and to focus on those that still need attention.\nWe encourage you to visit the Discussions section to share your thoughts, resources, or perspectives. If you identify a key question that has been overlooked, feel free to start a new discussion thread!",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "contribute.html#provide-feedback-questions-suggestions",
    "href": "contribute.html#provide-feedback-questions-suggestions",
    "title": "Contribute",
    "section": "Provide Feedback, Questions, Suggestions",
    "text": "Provide Feedback, Questions, Suggestions\nYour feedback is crucial to our progress. Please use the Issues area to share general feedback, ask questions, or make suggestions. You can also propose new paragraphs or information that you believe would be valuable for inclusion.",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "contribute.html#pull-requests",
    "href": "contribute.html#pull-requests",
    "title": "Contribute",
    "section": "Pull Requests",
    "text": "Pull Requests\nIf you are familiar with git, we welcome you to contribute directly by submitting Pull Requests. Your contributions are highly appreciated and will help improve the manuscript.",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "contribute.html#guidance",
    "href": "contribute.html#guidance",
    "title": "Contribute",
    "section": "Guidance",
    "text": "Guidance\n\nShare your thoughts and perspectives to enrich the discussions.\nProvide references to relevant articles, webinars, and presentations (citations and links are encouraged).\nMaintain a respectful and constructive tone within the community.\n\nYour active participation is essential to the success of this project. Together, we can advance our understanding and address the remaining questions effectively.",
    "crumbs": [
      "Contribute"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "17  Resources",
    "section": "",
    "text": "18 Resources for Open Source\n\nResource Link\n\n\n\n\n\n\nResource\nLink\n\n\n\n\nCAMIS Working Group (PSI/AIMS / PHUSE)\nhttps://psiaims.github.io/CAMIS/\n\n\nCDISC COSA\nhttps://www.cdisc.org/cosa\n\n\nDataset-JSON WG (CDISC\nPHUSE)\n\n\nModernization of Statistical Analytics Framework (Transcelerate)\nhttps://www.transceleratebiopharmainc.com/assets/modernization-of-statistical-analytics-solutions/\n\n\nOpen Pharma\nhttps://openpharma.github.io/\n\n\nOpen Source Portal for Clinical Study Evaluations\nhttps://www.glacon.eu/portal\n\n\nOpenStudyBuilder\nhttps://openstudybuilder.com/\n\n\npharmaverse\nhttps://pharmaverse.org/\n\n\nR Adoption Webinar Series (R Consortium)\nhttps://r-consortium.org/webinars/webinars.html\n\n\nR for Clinical Study Reports and Submission\nhttps://r4csr.org/\n\n\nR Submission Pilots (R Consortium)\nhttps://github.com/RConsortium/submissions-wg\n\n\nR Validation Hub White Paper\nhttps://www.pharmar.org/white-paper/\n\n\nEnd-to-End Open-source Collaboration Guidance\nhttps://phuse-org.github.io/E2E-OS-Guidance/",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bell, B. 2006. “Issues with Open Source Statistical Software in\nIndustry: Validation, Legal Issues, and Regulatory Requirements.”\nhttps://ww2.amstat.org/meetings/jsm/2006/onlineprogram/index.cfm?fuseaction=people_index&letter=B.\n\n\nBowsher, P. n.d.\n“Open-Source-in-New-Drug-Applications-NDAs-FDA.” https://github.com/philbowsher/Open-Source-in-New-Drug-Applications-NDAs-FDA.\n\n\nClark, Aaron, Robert Krajcik, Jeff Thompson, Lars Andersen, Andrew\nBorgman, Marly Gotti, Maya Gans, Aravind Reddy Kallem, and Fission Labs\nIndia Pvt Ltd. 2023. Riskassessment: A Web App Designed to Interface\nwith the ‘Riskmetric‘ Package. https://github.com/pharmaR/riskassessment.\n\n\nDrug Administration (FDA), U. S. Food &. 2015. “Statistical\nSoftware Clarifying Statement.” https://www.fda.gov/media/161196/download.\n\n\nHester, Jim. 2023. Covr: Test Coverage for Packages. https://covr.r-lib.org.\n\n\nKelkhoff, Doug, and Andrew McNeil. 2024. Covtracer: Tools for\nContextualizing Tests. https://github.com/genentech/covtracer.\n\n\nKnoph, Larsen, A. S. 2023. “Novo Nordisk’s Journey to an r Based\nFDA Submission.” https://www.youtube.com/watch?v=t33dS17QHuA.\n\n\nNeitman, Martin, T. 2023. “Shifting to an Open-Source Backbone in\nClinical Trials with Roche.” https://www.youtube.com/watch?v=nqJsLSLd39A.\n\n\n“R Consortium Submissions Working Group.” 2021. https://rconsortium.github.io/submissions-wg/.\n\n\nR Validation Hub, Doug Kelkhoff, Marly Gotti, Eli Miller, Kevin K,\nYilong Zhang, Eric Milliman, and Juliane Manitz. 2024. Riskmetric:\nRisk Metrics to Evaluating r Packages. https://pharmar.github.io/riskmetric/.\n\n\nRStudio Team. 2020. RStudio: Integrated Development Environment for\nr. Boston, MA: RStudio, PBC. http://www.rstudio.com/.\n\n\nSchuette, P. 2018. “Using r in a Regulatory Environment: Some FDA\nPerspectives.” https://rinpharma.com/publication/rinpharma_7/.\n\n\nSoukup, M. 2007. “Using r: Perspectives of a FDA Statistical\nRevieweR.” https://www.r-project.org/conferences/useR-2007/program/presentations/soukup.pdf;\nuseR.\n\n\n“Tidyverse, Tidymodels, r-Lib, and Gt r Packages: Regulatory\nCompliance and Validation Issues.” 2020. Posit / RStudio PBC. https://www.rstudio.com/assets/img/validation-tidy.pdf.\n\n\nWickham, Hadley, and Jenny Bryan. 2023. R Packages. O’Reilly\nMedia, Incorporated.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2024. Roxygen2: In-Line Documentation for r. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, and Maëlle Salmon. 2023. Pkgdown:\nMake Static HTML Documentation for a Package. https://pkgdown.r-lib.org.",
    "crumbs": [
      "References"
    ]
  }
]